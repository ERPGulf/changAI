{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1Ydr4_57fpz7tluIEVymVFuNrzM0eB2hr",
      "authorship_tag": "ABX9TyPpoL1WYzo1fQtsFWc5xt7D"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yto-5STKkpnt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
      ],
      "metadata": {
        "id": "ywyBw2XqmBjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "# Load your dataset\n",
        "with open('/content/intent_classification_erp_dataset_updated.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Add prompt to each text\n",
        "prompt = \"Classify the intent of the following query: \"\n",
        "data = [{\"input\": prompt + item[\"input\"], \"output\": item[\"output\"]} for item in data]\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_list(data)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Label mapping\n",
        "unique_labels = sorted(set(item[\"output\"] for item in data))\n",
        "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
        "id2label = {i: label for i, label in enumerate(unique_labels)}\n",
        "tokenized_dataset = tokenized_dataset.map(lambda x: {\"label\": label2id[x[\"output\"]]})\n",
        "with open('id2label.json', 'w') as f:\n",
        "    json.dump(id2label, f)\n",
        "with open('label2id.json', 'w') as f:\n",
        "    json.dump(label2id, f)"
      ],
      "metadata": {
        "id": "P8VPXFVEkyUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "eval_dataset = split_dataset[\"test\"]"
      ],
      "metadata": {
        "id": "0vV-GUI6lB9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\",\n",
        "    num_labels=len(unique_labels)\n",
        ")"
      ],
      "metadata": {
        "id": "vq6QaB8qlEBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "LwvVDocjldT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n"
      ],
      "metadata": {
        "id": "sO8xk7yMlgD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "sbnAca2slhkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"/content/drive/MyDrive/roberta_intent_classifier\"\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)"
      ],
      "metadata": {
        "id": "DP27cDvbljC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    # ERP Complete Intent: Uncommon or complex ERP requests\n",
        "    {\"query\": \"Show invoices created today with PO number filled in.\", \"expected_intent\": \"erp_complete\"},\n",
        "    {\"query\": \"Do any invoices have PO details referencing 'Urgent'?\", \"expected_intent\": \"erp_complete\"},\n",
        "    {\"query\": \"Find invoices where customer PO info includes 'QTR2025'.\", \"expected_intent\": \"erp_complete\"},\n",
        "    {\"query\": \"How many POS invoices had customer PO data?\", \"expected_intent\": \"erp_complete\"},\n",
        "]\n"
      ],
      "metadata": {
        "id": "mbxXeoTOlpXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Load your model and tokenizer\n",
        "model_dir = \"/content/drive/MyDrive/roberta_intent_classifier\"\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model_dir,\n",
        "    tokenizer=model_dir,\n",
        "    device=0 if torch.cuda.is_available() else -1,\n",
        ")\n",
        "\n",
        "# Your label mapping (example - adjust to your actual mapping)\n",
        "id2label={0: \"complete_question\",\n",
        "          1: \"erp_complete\",\n",
        "          2: \"followup_or_clarification\",\n",
        "          3: \"greeting\",\n",
        "          4: \"out_of_scope\"\n",
        "          }\n",
        "\n",
        "for case in test_cases:\n",
        "    query = case[\"query\"]\n",
        "    result = classifier(query)\n",
        "    predicted_label = result[0]['label']\n",
        "    label_id = int(predicted_label.split('_')[1])\n",
        "    predicted_intent = id2label[label_id]\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"Predicted intent: {predicted_intent}\")\n",
        "    print(f\"Expected intent: {case['expected_intent']}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "id": "HMfV4QjrlpT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}