{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "https://github.com/ERPGulf/changai/blob/hyrin/changai/notebooks/s2_flan.ipynb",
      "authorship_tag": "ABX9TyNcf6SjyeERc8GvrEPbUclD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "id": "KhtBtCw0nbHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKd7BEG0mZO4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 3: Load your JSON dataset and preprocess (REMOVE instruction, add instruction dynamically)\n",
        "with open('/content/drive/MyDrive/Changai/S2/S2 Datasets/S2_flan_new (1).json') as f:\n",
        "    raw_data = json.load(f)"
      ],
      "metadata": {
        "id": "6dDT6s65nJVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Library\n",
        "import json\n",
        "\n",
        "# Hugging Face Libraries\n",
        "from datasets import Dataset\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from transformers import DataCollatorForSeq2Seq"
      ],
      "metadata": {
        "id": "dOcY7Az4ngOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INSTRUCTION = \"Select only the correct field(s) from the given top fields that answer the question.\"\n",
        "with open('/content/S2_flan_new.json') as f:\n",
        "    raw_data = json.load(f)\n",
        "formatted_data = []\n",
        "for entry in raw_data:\n",
        "    inp = entry[\"input\"]\n",
        "    prompt = f\"Instruction: {INSTRUCTION}\\nDoctype: {inp['doctype']}\\nQuestion: {inp['question']}\\nTop Fields: {inp['top fields']}\"\n",
        "    output = ', '.join(entry[\"output\"])\n",
        "    formatted_data.append({\"input\": prompt, \"output\": output})\n",
        "\n",
        "# Convert to HuggingFace Dataset\n",
        "dataset = Dataset.from_list(formatted_data)\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = dataset[\"train\"]\n",
        "val_dataset = dataset[\"test\"]\n",
        "\n",
        "# ======================\n",
        "# STEP 2: Load FLAN-T5 and tokenizer\n",
        "# ======================\n",
        "model_name = \"google/flan-t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# ======================\n",
        "# STEP 3: Tokenize\n",
        "# ======================\n",
        "def tokenize_fn(example):\n",
        "    model_inputs = tokenizer(\n",
        "        example[\"input\"],\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        example[\"output\"],\n",
        "        max_length=64,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "# ======================\n",
        "# STEP 4: Training setup\n",
        "# ======================\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Changai/S2/S2 Model/flan_field_selector_final\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=6,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Changai/S2/S2 Model/flan_field_selector_final\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Changai/S2/S2 Model/flan_field_selector_final\")"
      ],
      "metadata": {
        "id": "yCW2cE1ToliK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Changai/S2/S2 Model/flan_field_selector_final/checkpoint-180\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)\n",
        "tokenizer = T5Tokenizer.from_pretrained(checkpoint_path)\n"
      ],
      "metadata": {
        "id": "y2Qo2tmDRJVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/Changai/S2/S2 Model/flan_s3_query_generator_new\"\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n"
      ],
      "metadata": {
        "id": "YWF_-T5OSy8M",
        "outputId": "cf96816d-d391-4181-b4db-5eb7fe535e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Changai/S2/S2 Model/flan_s3_query_generator_new/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Changai/S2/S2 Model/flan_s3_query_generator_new/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Changai/S2/S2 Model/flan_s3_query_generator_new/spiece.model',\n",
              " '/content/drive/MyDrive/Changai/S2/S2 Model/flan_s3_query_generator_new/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    \"\"\"Instruction: Select only the correct field(s) from the given top fields that answer the question.\n",
        "Doctype: Purchase Invoice Advance\n",
        "Question: What is the document type linked to advance entry ADV-9668?\n",
        "Top Fields: [reference_name,reference_type, advance_amount, allocated_amount, ref_exchange_rate, remarks]\"\"\",\n",
        "\n",
        "    \"\"\"Instruction: Select only the correct field(s) from the given top fields that answer the question.\n",
        "Doctype: Purchase Invoice Advance\n",
        "Question: List the reference types used in advance payments made this month.\n",
        "Top Fields: [reference_type, reference_name, difference_posting_date, advance_amount, allocated_amount, exchange_gain_loss]\"\"\",\n",
        "\n",
        "    \"\"\"Instruction: Select only the correct field(s) from the given top fields that answer the question.\n",
        "Doctype: Purchase Invoice Advance\n",
        "Question: Which advance entries are connected to a 'Purchase Invoice'?\n",
        "Top Fields: [reference_type, advance_amount, reference_name, allocated_amount, exchange_gain_loss]\"\"\",\n",
        "\n",
        "    \"\"\"Instruction: Select only the correct field(s) from the given top fields that answer the question.\n",
        "Doctype: Purchase Invoice Advance\n",
        "Question: Is there any advance entry linked to an 'Expense Claim'?\n",
        "Top Fields: [reference_type, advance_amount, reference_name, allocated_amount, ref_exchange_rate]\"\"\",\n",
        "\n",
        "    \"\"\"Instruction: Select only the correct field(s) from the given top fields that answer the question.\n",
        "Doctype: Purchase Invoice Advance\n",
        "Question: Retrieve the allocated amount and document ID for the entry ADV-5412.\n",
        "Top Fields: [reference_name, allocated_amount, ref_exchange_rate, remarks, advance_amount]\"\"\",\n",
        "\n",
        "    \"\"\"Instruction: Select only the correct field(s) from the given top fields that answer the question.\n",
        "Doctype: Purchase Invoice Advance\n",
        "Question: What is the exchange rate applied to the reference document of advance ADV-7771?\n",
        "Top Fields: [ref_exchange_rate, difference_posting_date, exchange_gain_loss, reference_type]\"\"\"\n",
        "]\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load model\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/Changai/S2/S2 Model/flan_field_selector_final\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/drive/MyDrive/Changai/S2/S2 Model/flan_field_selector_final\")\n",
        "\n",
        "def predict_field(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(inputs[\"input_ids\"], max_length=64)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Run predictions\n",
        "for i, case in enumerate(test_cases):\n",
        "    print(f\"\\n--- Test Case {i+1} ---\")\n",
        "    print(\"Input:\\n\", case)\n",
        "    print(\"Prediction:\\n\", predict_field(case))\n"
      ],
      "metadata": {
        "id": "55f-TMhSpCXr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}